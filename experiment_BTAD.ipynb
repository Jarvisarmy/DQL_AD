{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import ast\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions import MultivariateNormal\n",
    "from IPython.display import clear_output\n",
    "import scipy.ndimage as ndimage\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import metrics\n",
    "import joblib\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "from enum import Enum\n",
    "import faiss\n",
    "\n",
    "from dataloaders import dataloader_MVTec_setup\n",
    "from utils import get_files_masks, evaluate\n",
    "from evaluate import evaluate_metrics, get_scores, load_model, visualize_result\n",
    "from DQN import DQN\n",
    "from environment import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tuple(value):\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        raise argparse.ArgumentTypeError(f\"Invalid tuple: {value}\")\n",
    "parser = argparse.ArgumentParser()\n",
    "# ------------ \n",
    "# setup\n",
    "# ------------\n",
    "parser.add_argument(\"--use_gpu\", action=\"store_true\", help=\"Use GPU for training\")\n",
    "#parser.add_argument(\"--data_root\", type=str, default= \"./../../../../scratch-beauty/zzhan762/data/MVTec_AD\")\n",
    "#parser.add_argument(\"--data_root\", type=str, default= \"./mvtec\")\n",
    "#parser.add_argument(\"--data_root\", type=str, default= \"./data/mvtec\")\n",
    "parser.add_argument(\"--data_root\", type=str, default= \"./data/BTech_Dataset_transformed\")\n",
    "parser.add_argument(\"--verbose\", type=bool, default=True)\n",
    "# ------------------ \n",
    "# feature extractor\n",
    "# ------------------\n",
    "parser.add_argument(\"--target_size\", type=parse_tuple, default=\"(256,256)\")\n",
    "parser.add_argument(\"--resize_size\", type=parse_tuple, default=\"(256,256)\")\n",
    "parser.add_argument(\"--class_name\", type=str, default=\"toothbrush\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=8)\n",
    "parser.add_argument(\"--patch_size\",type=int, default=3)\n",
    "parser.add_argument(\"--target_embed_dimension\", type=int, default=1024)\n",
    "parser.add_argument(\"--edc\", action=\"store_true\")\n",
    "parser.add_argument(\"--backbone\", type=str,default=\"wide_resnet50_2\")\n",
    "parser.add_argument(\"--preprocessing_dimension\", type=int, default=1024)\n",
    "\n",
    "# ------------\n",
    "# DQN \n",
    "# ------------\n",
    "parser.add_argument(\"--action_dim\", type=int, default=2)\n",
    "parser.add_argument(\"--max_steps\",type=int, default=int(4e4))\n",
    "parser.add_argument(\"--eval_interval\", type=int, default =int(1e3))\n",
    "parser.add_argument(\"--lr\",type=float,default = 0.00025)\n",
    "parser.add_argument(\"--epsilon\",type=float,default=1.0)\n",
    "parser.add_argument(\"--epsilon_min\",type=float,default=0.1)\n",
    "parser.add_argument(\"--gamma\", type=float, default=0.99)\n",
    "parser.add_argument(\"--dqn_batch_size\",type=int,default=32)\n",
    "parser.add_argument(\"--warmup_steps\",type=int, default=int(2e3))\n",
    "parser.add_argument(\"--buffer_size\",type=int,default=int(5e3))\n",
    "parser.add_argument(\"--target_update_interval\",type=int,default=int(5e3))\n",
    "\n",
    "# ---------------\n",
    "# Envirnment\n",
    "# ---------------\n",
    "parser.add_argument(\"--prob\", type=float, default=0.5)\n",
    "parser.add_argument(\"--max_samples\",type=float,default=40)\n",
    "parser.add_argument(\"--iForest_update_interval\",type=int,default=int(2e3))\n",
    "parser.add_argument(\"--iForest_max_samples\",type=float,default=0.3)\n",
    "parser.add_argument(\"--iForest_total_samples\",type=int,default=int(1e6))\n",
    "parser.add_argument(\"--iForest_batch_size\",type=int,default=1024)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# components\n",
    "# -----------------------\n",
    "parser.add_argument(\"--use_prioritized\", type=bool, default=False)\n",
    "parser.add_argument(\"--use_intrinsic\",type=bool, default=False)\n",
    "parser.add_argument(\"--use_copypaste\", type=bool, default=False)\n",
    "parser.add_argument(\"--use_faiss\", type=bool, default=False)\n",
    "\n",
    "\n",
    "args = parser.parse_args(['--use_gpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.use_gpu else \"cpu\")\n",
    "print('device: {}'.format(device))\n",
    "args.backbone = 'wide_resnet50_2'\n",
    "args.layers = ['layer2','layer3']\n",
    "args.hidden_sizes = [512,256,128]\n",
    "args.state_dim = args.target_embed_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_masks(dataroot,class_name,target_types, unknown_types,train_num, verbose=False):\n",
    "    trainpath = os.path.join(dataroot,class_name,'train','good')\n",
    "    testpath = os.path.join(dataroot, class_name,'test')\n",
    "    maskpath = os.path.join(dataroot, class_name, \"ground_truth\")\n",
    "    train_normal_files = sorted(os.listdir(trainpath))\n",
    "    train_normal_files = [os.path.join(trainpath,x) for x in train_normal_files]\n",
    "\n",
    "    # test normal files\n",
    "    test_normal_files = sorted(os.listdir(os.path.join(testpath,'good')))\n",
    "    test_normal_files = [os.path.join(testpath,'good',x) for x in test_normal_files]\n",
    "    train_target_files = []\n",
    "    train_target_masks = []\n",
    "    test_target_files = []\n",
    "    test_target_masks = []\n",
    "    for anomaly in target_types:\n",
    "        anomaly_path = os.path.join(testpath,anomaly)\n",
    "        anomaly_files = sorted(os.listdir(anomaly_path))\n",
    "        mask_files = sorted(os.listdir(os.path.join(maskpath,anomaly)))\n",
    "        for i, (file,mask_file) in enumerate(zip(anomaly_files,mask_files)):\n",
    "            #name, extension = os.path.splitext(file)\n",
    "            #mask_file = name+extension\n",
    "            if i < train_num:\n",
    "                train_target_files.append(os.path.join(anomaly_path,file))\n",
    "                train_target_masks.append(os.path.join(maskpath,anomaly,mask_file))\n",
    "            else:\n",
    "                test_target_files.append(os.path.join(anomaly_path,file))\n",
    "                test_target_masks.append(os.path.join(maskpath,anomaly,mask_file))\n",
    "\n",
    "    # train unknown files\n",
    "    # test unknown files\n",
    "    train_unknown_files = []\n",
    "    train_unknown_masks = []\n",
    "    test_unknown_files = []\n",
    "    test_unknown_masks = []\n",
    "    for anomaly in unknown_types:\n",
    "        anomaly_path = os.path.join(testpath,anomaly)\n",
    "        anomaly_files = sorted(os.listdir(anomaly_path))\n",
    "        mask_files = sorted(os.listdir(os.path.join(maskpath,anomaly)))\n",
    "        for i, (mask_file,file) in enumerate(zip(anomaly_files,mask_files)):\n",
    "            #name, extension = os.path.splitext(file)\n",
    "            #mask_file = name+extension\n",
    "            if i < train_num:\n",
    "                train_unknown_files.append(os.path.join(anomaly_path,file))\n",
    "                train_unknown_masks.append(os.path.join(maskpath,anomaly,mask_file))\n",
    "            else:\n",
    "                test_unknown_files.append(os.path.join(anomaly_path,file))\n",
    "                test_unknown_masks.append(os.path.join(maskpath,anomaly,mask_file))   \n",
    "    \n",
    "    files_dict = {'train_normal_files': train_normal_files, \n",
    "                  'train_target_files': train_target_files,\n",
    "                  'train_target_masks': train_target_masks,\n",
    "                  'train_unknown_files': train_unknown_files,\n",
    "                  'train_unknown_masks': train_unknown_masks,\n",
    "                  'test_normal_files': test_normal_files,\n",
    "                  'test_target_files': test_target_files,\n",
    "                  'test_target_masks': test_target_masks,\n",
    "                  'test_unknown_files': test_unknown_files,\n",
    "                  'test_unknown_masks': test_unknown_masks,}\n",
    "    if verbose:\n",
    "        for item, value in files_dict.items():\n",
    "            print(\"{}: {}\".format(item, len(value)))\n",
    "    return files_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_normal_files: 400\n",
      "train_target_files: 1\n",
      "train_target_masks: 1\n",
      "train_unknown_files: 0\n",
      "train_unknown_masks: 0\n",
      "test_normal_files: 21\n",
      "test_target_files: 48\n",
      "test_target_masks: 48\n",
      "test_unknown_files: 0\n",
      "test_unknown_masks: 0\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 1024, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "classes = [item for item in os.listdir(args.data_root) if not item.endswith('.txt')]\n",
    "#classes = [\"bottle\",\"cable\",\"capsule\",\"carpet\",\"grid\",\"hazelnut\",\"leather\",\"metal_nut\",\"pill\",\"screw\",\"tile\",\"toothbrush\",\"transistor\",\"wood\",\"zipper\"]\n",
    "#classes = [\"carpet\",\"grid\",\"hazelnut\",\"leather\",\"metal_nut\",\"pill\",\"screw\",\"tile\",\"toothbrush\",\"transistor\",\"wood\",\"zipper\"]\n",
    "assert (len(classes) == 3)\n",
    "for class_name in classes:\n",
    "    torch.cuda.empty_cache()\n",
    "    args.class_name = class_name\n",
    "    target_types = [item for item in os.listdir(os.path.join(args.data_root, args.class_name,'test')) if item != 'good']\n",
    "    unknown_types = []\n",
    "    files_dict = get_files_masks(args.data_root,args.class_name,target_types,unknown_types,1,verbose=True)\n",
    "    agent = DQN(args,device=device)\n",
    "    env = Environment(files_dict['train_normal_files'],\n",
    "                    files_dict['train_target_files'],\n",
    "                    files_dict['train_target_masks'],args,device)\n",
    "    env.update_subsamples(agent.network)\n",
    "    #env.initialize(agent.network)\n",
    "    eval_env = Environment(files_dict['train_normal_files'],\n",
    "                        files_dict['train_target_files'],\n",
    "                        files_dict['train_target_masks'],args,device,eval=True)\n",
    "    eval_env.update_subsamples(agent.network)\n",
    "    history = {'Step':[],'AvgReturn':[],'auroc':[],'i_auroc':[]}\n",
    "    s = env.reset()\n",
    "    best_result = 0\n",
    "    while True:\n",
    "        action = agent.act(s)\n",
    "        next_state, reward, terminated, truncated, info = env.step(agent.network,action)\n",
    "        result = agent.process((s, action, reward, next_state, terminated))\n",
    "        s = next_state\n",
    "        if terminated or truncated:\n",
    "            s = env.reset()\n",
    "        if agent.total_steps % args.eval_interval == 0:\n",
    "            #eval_env.copy_from_env(env)\n",
    "            ret = evaluate(eval_env,agent)\n",
    "            checkpoint = {\n",
    "                'model': agent.network.state_dict(),\n",
    "                'args': args,\n",
    "                'files_dict':files_dict\n",
    "            }\n",
    "            checkpoint_path = os.path.join('checkpoints/BTAD_1_None','dqn_'+class_name +'_1.pt')\n",
    "            torch.save(checkpoint,checkpoint_path)\n",
    "            scores_dict = get_scores(checkpoint_path,device)\n",
    "            norm_scores = (scores_dict['total_scores']-scores_dict['total_scores'].min())/(scores_dict['total_scores'].max()-(scores_dict['total_scores'].min()))\n",
    "            result = evaluate_metrics(scores_dict['total_labels'],norm_scores)\n",
    "            cur_res = (result['auroc'] + result['i_auroc'])/2\n",
    "            if cur_res >= best_result:\n",
    "                best_result=cur_res\n",
    "                torch.save(checkpoint,os.path.join('checkpoints/BTAD_1_None','dqn_'+class_name +'_1_best.pt'))\n",
    "            history['Step'].append(agent.total_steps)\n",
    "            history['AvgReturn'].append(ret)\n",
    "            history['auroc'].append(result['auroc'])\n",
    "            history['i_auroc'].append(result['i_auroc'])\n",
    "            clear_output()\n",
    "            print(class_name)\n",
    "            fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(12,3))\n",
    "            ax1.plot(history['Step'],history['AvgReturn'],'r-')\n",
    "            ax1.set_xlabel('Step',fontsize=16)\n",
    "            ax1.set_ylabel('AvgReturn', fontsize=16)\n",
    "            ax1.grid(axis='y')\n",
    "            ax2.plot(history['Step'],history['auroc'],'r-')\n",
    "            ax2.set_xlabel('Step',fontsize=16)\n",
    "            ax2.set_ylabel('AUROC', fontsize=16)\n",
    "            ax2.grid(axis='y')\n",
    "            ax3.plot(history['Step'],history['i_auroc'],'r-')\n",
    "            ax3.set_xlabel('Step',fontsize=16)\n",
    "            ax3.set_ylabel('IAUROC', fontsize=16)\n",
    "            ax3.grid(axis='y')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join('checkpoints/BTAD_1_None','dqn_'+class_name +'_1.png'))\n",
    "            plt.show()\n",
    "        if agent.total_steps > args.max_steps:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 1024, 16, 16])\n",
      "auroc: 0.9847047742673309\n",
      "auprc: 0.6728562875319548\n",
      "aupro: 0.5738668740141769\n",
      "thres: 0.9996626973152161\n",
      "image_thres: 0.8055776357650757\n",
      "i_auroc: 1.0\n",
      "i_auprc: 1.0\n",
      "f1: 1.0\n",
      "accuracy: 1.0\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 1024, 16, 16])\n",
      "auroc: 0.973549302797679\n",
      "auprc: 0.798400240385052\n",
      "aupro: 0.10246835928752002\n",
      "thres: 0.9998587965965271\n",
      "image_thres: 0.0\n",
      "i_auroc: 0.7914630172694689\n",
      "i_auprc: 0.964090986608401\n",
      "f1: 0.927400468384075\n",
      "accuracy: 0.8646288209606987\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 1024, 16, 16])\n",
      "auroc: 0.975049182988505\n",
      "auprc: 0.614723935957781\n",
      "aupro: 0.39389380061893564\n",
      "thres: 0.8374662399291992\n",
      "image_thres: 0.9940745830535889\n",
      "i_auroc: 0.9953252032520324\n",
      "i_auprc: 0.935221666508814\n",
      "f1: 0.9180327868852459\n",
      "accuracy: 0.9886363636363636\n",
      "0.9777677533511717\n",
      "0.9289294068405004\n"
     ]
    }
   ],
   "source": [
    "classes = [item for item in os.listdir(args.data_root) if not item.endswith('.txt')]\n",
    "#classes = [\"toothbrush\"]\n",
    "assert (len(classes) == 3)\n",
    "IAUROC = 0\n",
    "PAUROC = 0\n",
    "for class_name in classes:\n",
    "    checkpoint_path = './checkpoints/BTAD_1/dqn_'+class_name + '_1_best.pt'\n",
    "    scores_dict = get_scores(checkpoint_path,device)\n",
    "    norm_scores = (scores_dict['total_scores']-scores_dict['total_scores'].min())/(scores_dict['total_scores'].max()-(scores_dict['total_scores'].min()))\n",
    "    result = evaluate_metrics(scores_dict['total_labels'],norm_scores)\n",
    "    PAUROC += result['auroc']\n",
    "    IAUROC += result['i_auroc']\n",
    "print(PAUROC/3)\n",
    "print(IAUROC/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './checkpoints/final_1/dqn_zipper_10_best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/final_1/dqn_zipper_10_best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m scores_dict \u001b[38;5;241m=\u001b[39m get_scores(checkpoint_path,device)\n\u001b[0;32m      3\u001b[0m norm_scores \u001b[38;5;241m=\u001b[39m (scores_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39mscores_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;241m/\u001b[39m(scores_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m-\u001b[39m(scores_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()))\n\u001b[0;32m      5\u001b[0m evaluate_metrics(scores_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_labels\u001b[39m\u001b[38;5;124m'\u001b[39m],norm_scores)\n",
      "File \u001b[1;32mc:\\Users\\Jarvis\\Desktop\\RL_AD\\evaluate.py:15\u001b[0m, in \u001b[0;36mget_scores\u001b[1;34m(checkpoint_path, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_scores\u001b[39m(checkpoint_path,device):\n\u001b[1;32m---> 15\u001b[0m     agent, args \u001b[38;5;241m=\u001b[39m load_model(checkpoint_path)\n\u001b[0;32m     16\u001b[0m     target_types \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mdata_root, args\u001b[38;5;241m.\u001b[39mclass_name,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgood\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m     unknown_types \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Jarvis\\Desktop\\RL_AD\\evaluate.py:141\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(checkpoint_path)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(checkpoint_path):\n\u001b[1;32m--> 141\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path)\n\u001b[0;32m    142\u001b[0m     args \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    143\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jarvis\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Jarvis\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Jarvis\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints/final_1/dqn_zipper_10_best.pt'"
     ]
    }
   ],
   "source": [
    "checkpoint_path = './checkpoints/final_1/dqn_zipper_10_best.pt'\n",
    "scores_dict = get_scores(checkpoint_path,device)\n",
    "norm_scores = (scores_dict['total_scores']-scores_dict['total_scores'].min())/(scores_dict['total_scores'].max()-(scores_dict['total_scores'].min()))\n",
    "\n",
    "evaluate_metrics(scores_dict['total_labels'],norm_scores)\n",
    "visualize_result(8,scores_dict['total_imgs'],scores_dict['total_labels'],norm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
